{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ],
   "execution_count":30,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"FuDXGiq6zd4J1EfWD9b7go",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!pip install nltk"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: nltk in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from nltk) (2023.8.8)\r\n",
      "Requirement already satisfied: tqdm in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from nltk) (4.66.1)\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"MzvX5vHm2HexJX9OTAJr6K",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install --upgrade pip"
   ],
   "execution_count":15,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: pip in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (23.2.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"8jVcGpxt6NojzjVwXWv9aI",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df = pd.read_csv('\/data\/notebook_files\/ConcordiaChat_ulfiltered.csv')"
   ],
   "execution_count":16,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"P3FrpXVUncOmi8cKzY6Tz1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df"
   ],
   "execution_count":17,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>Date<\/th>\n",
       "      <th>Username<\/th>\n",
       "      <th>User tag<\/th>\n",
       "      <th>Content<\/th>\n",
       "      <th>Mentions<\/th>\n",
       "      <th>link<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>2023-01-13,12:37:44<\/td>\n",
       "      <td>bougaa<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>Anybody here with cloud experience? and or wor...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>2023-01-13,15:45:12<\/td>\n",
       "      <td>\"Eyad Abou Ker[IGT]+[CDH]\"<\/td>\n",
       "      <td>#1826<\/td>\n",
       "      <td>Hi anyone here with good knowledge in HTML CSS...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>2023-01-13,17:15:41<\/td>\n",
       "      <td>felixfelixfelix<\/td>\n",
       "      <td>#5119<\/td>\n",
       "      <td>We're a team mainly comprised of data scientis...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>2023-01-13,19:30:59<\/td>\n",
       "      <td>DankDora<\/td>\n",
       "      <td>#3469<\/td>\n",
       "      <td>Hello! Looking for 2 more members! Iâ€™m a stude...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>2023-01-13,21:40:58<\/td>\n",
       "      <td>roco5marco<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>Hey guys! I'm a first year software engineerin...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>...<\/th>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>158<\/th>\n",
       "      <td>2023-01-22,15:02:27<\/td>\n",
       "      <td>al3x7643<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>Who?<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>159<\/th>\n",
       "      <td>2023-01-22,16:48:47<\/td>\n",
       "      <td>Darkok<\/td>\n",
       "      <td>#9818<\/td>\n",
       "      <td>Am down for some unpaid internship I only have...<\/td>\n",
       "      <td>yusufr#0<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>160<\/th>\n",
       "      <td>2023-01-22,16:49:38<\/td>\n",
       "      <td>yusufr<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>Sorry, your qualifications are insufficient fo...<\/td>\n",
       "      <td>Darkok#9818<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>161<\/th>\n",
       "      <td>2023-01-22,16:52:33<\/td>\n",
       "      <td>Darkok<\/td>\n",
       "      <td>#9818<\/td>\n",
       "      <td>I forgot to mention that am currently trying t...<\/td>\n",
       "      <td>yusufr#0<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>162<\/th>\n",
       "      <td>2023-01-22,16:53:19<\/td>\n",
       "      <td>yusufr<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>Unfortunately, you need to be able to build AI...<\/td>\n",
       "      <td>Darkok#9818<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<p>163 rows Ã— 6 columns<\/p>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Z7tv31zFwhWPlo7wC1f2zC",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy=df"
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"PeC23cvR5asncIAEmKlW4C",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy[\"Content\"]=df_copy[\"Content\"].apply(clean)\n",
    "df_copy"
   ],
   "execution_count":19,
   "outputs":[
    {
     "ename":"NameError",
     "evalue":"NameError: name 'clean' is not defined",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 1 in <module>",
      "NameError: name 'clean' is not defined"
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"F8Tvl7XjitQK4936UNqN0F",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy[\"Content\"]"
   ],
   "execution_count":7,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>0      anybody here with cloud experience? and or wor...\n",
       "1      hi anyone here with good knowledge in html css...\n",
       "2      we're a team mainly comprised of data scientis...\n",
       "3      hello! looking for 2 more members! iâ€™m a stude...\n",
       "4      hey guys! i'm a first year software engineerin...\n",
       "                             ...                        \n",
       "158                                                 who?\n",
       "159    am down for some unpaid internship i only have...\n",
       "160    sorry, your qualifications are insufficient fo...\n",
       "161    i forgot to mention that am currently trying t...\n",
       "162    unfortunately, you need to be able to build ai...\n",
       "Name: Content, Length: 163, dtype: object<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"tgU2t91YIQLxTauI6DhzM5",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def clean(content):\n",
    "    #Clear bracketed texts\n",
    "    content=re.sub(r'<[^>]*>','',content)\n",
    "    #Remove url\n",
    "    content = re.sub(r'http\\S+', 'URL', content)\n",
    "    #Clear punctuations\n",
    "    content = re.sub(r'[^\\w\\s]+', ' ', content)\n",
    "    #remove extra spaces\n",
    "    content = ' '.join(content.lower().split())\n",
    "\n",
    "    return content\n"
   ],
   "execution_count":35,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"lNAlUKuupyJu48codeU2de",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#test\n",
    "example1=\"<@756516000454672487> hi brahim:) , Here ðŸ™‚ are some of my projects: https:\/\/www.linkedin.com\/in\/brahim-hamid-oudjana-35023a123\/i <sdskhd> sent??... you a dm!!\"\n",
    "cleaned_example1=clean(example1)"
   ],
   "execution_count":29,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"6lYJh3OLukprCzEL1d3bY5",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy[\"Content\"]=df_copy[\"Content\"].apply(clean)\n",
    "df_copy"
   ],
   "execution_count":37,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>Date<\/th>\n",
       "      <th>Username<\/th>\n",
       "      <th>User tag<\/th>\n",
       "      <th>Content<\/th>\n",
       "      <th>Mentions<\/th>\n",
       "      <th>link<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>2023-01-13,12:37:44<\/td>\n",
       "      <td>bougaa<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>anybody here with cloud experience and or work...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>2023-01-13,15:45:12<\/td>\n",
       "      <td>\"Eyad Abou Ker[IGT]+[CDH]\"<\/td>\n",
       "      <td>#1826<\/td>\n",
       "      <td>hi anyone here with good knowledge in html css...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>2023-01-13,17:15:41<\/td>\n",
       "      <td>felixfelixfelix<\/td>\n",
       "      <td>#5119<\/td>\n",
       "      <td>we re a team mainly comprised of data scientis...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>2023-01-13,19:30:59<\/td>\n",
       "      <td>DankDora<\/td>\n",
       "      <td>#3469<\/td>\n",
       "      <td>hello looking for 2 more members i m a student...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>2023-01-13,21:40:58<\/td>\n",
       "      <td>roco5marco<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>hey guys i m a first year software engineering...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>...<\/th>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>158<\/th>\n",
       "      <td>2023-01-22,15:02:27<\/td>\n",
       "      <td>al3x7643<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>who<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>159<\/th>\n",
       "      <td>2023-01-22,16:48:47<\/td>\n",
       "      <td>Darkok<\/td>\n",
       "      <td>#9818<\/td>\n",
       "      <td>am down for some unpaid internship i only have...<\/td>\n",
       "      <td>yusufr#0<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>160<\/th>\n",
       "      <td>2023-01-22,16:49:38<\/td>\n",
       "      <td>yusufr<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>sorry your qualifications are insufficient for...<\/td>\n",
       "      <td>Darkok#9818<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>161<\/th>\n",
       "      <td>2023-01-22,16:52:33<\/td>\n",
       "      <td>Darkok<\/td>\n",
       "      <td>#9818<\/td>\n",
       "      <td>i forgot to mention that am currently trying t...<\/td>\n",
       "      <td>yusufr#0<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>162<\/th>\n",
       "      <td>2023-01-22,16:53:19<\/td>\n",
       "      <td>yusufr<\/td>\n",
       "      <td>#0<\/td>\n",
       "      <td>unfortunately you need to be able to build ai ...<\/td>\n",
       "      <td>Darkok#9818<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<p>163 rows Ã— 6 columns<\/p>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"gkFpOHqtIqn5aB3sEIinKL",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "token=word_tokenize(cleaned_example1)\n",
    "token"
   ],
   "execution_count":34,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "['hi',\n",
       " 'brahim',\n",
       " 'here',\n",
       " 'are',\n",
       " 'some',\n",
       " 'of',\n",
       " 'my',\n",
       " 'projects',\n",
       " 'url',\n",
       " 'sent',\n",
       " 'you',\n",
       " 'a',\n",
       " 'dm']"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"v4ho1hFOCL0Kg5KKuxeZaj",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def tokenise_chat(chat_text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(chat_text)\n",
    "    # Remove stopwords\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stopwords_list]\n",
    "    return tokens"
   ],
   "execution_count":36,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"J9oP6NVYCJr5so6MSmlPYG",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy[\"Content\"]=df_copy[\"Content\"].apply(tokenise_chat)"
   ],
   "execution_count":38,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"CDRiNyeRAHIuOWr6XWvqOR",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_copy[\"Content\"]"
   ],
   "execution_count":39,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>0      [anybody, cloud, experience, worked, mysql, py...\n",
       "1      [hi, anyone, good, knowledge, html, css, js, t...\n",
       "2      [team, mainly, comprised, data, scientists, 2,...\n",
       "3      [hello, looking, 2, members, student, mechanic...\n",
       "4      [hey, guys, first, year, software, engineering...\n",
       "                             ...                        \n",
       "158                                                   []\n",
       "159    [unpaid, internship, 13, years, experience, fa...\n",
       "160    [sorry, qualifications, insufficient, entry, l...\n",
       "161    [forgot, mention, currently, trying, build, ai...\n",
       "162    [unfortunately, need, able, build, ai, blockch...\n",
       "Name: Content, Length: 163, dtype: object<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"cG2edJaJD4Y73H4YYhdEnG",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Create and train the Word2Vec model\n",
    "model = Word2Vec(sentences=df_copy[\"Content\"], vector_size=100, window=5, min_count=1, sg=0)"
   ],
   "execution_count":53,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"S0k9b2aiSYbXMZh6t9ZfWy",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "vector = model.wv[\"concordia\"]\n",
    "vector"
   ],
   "execution_count":54,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>array([-0.00381608,  0.00241902,  0.00210885, -0.0085262 ,  0.00496175,\n",
       "       -0.00216112,  0.00244017,  0.00444478, -0.01052132,  0.00644995,\n",
       "       -0.01122686, -0.01267814,  0.00497312, -0.00689173, -0.00201129,\n",
       "       -0.0043258 , -0.00103722, -0.01006234,  0.0034416 , -0.00618085,\n",
       "        0.00573569,  0.00070793,  0.00840892, -0.01023972,  0.00400248,\n",
       "       -0.00452971, -0.0012879 , -0.01008576, -0.00451492, -0.00532361,\n",
       "        0.00014906,  0.01076667,  0.00350539, -0.00097551, -0.00874674,\n",
       "        0.01038571, -0.00873024, -0.00525823, -0.00926857, -0.01272822,\n",
       "        0.00301051, -0.00534607,  0.00032866,  0.00384802, -0.00289137,\n",
       "       -0.00221047, -0.00459621, -0.01275128, -0.00811341,  0.0023511 ,\n",
       "        0.00711468, -0.00268828, -0.00451408,  0.00206229, -0.00083276,\n",
       "       -0.00777659,  0.00799585,  0.00697017, -0.01246418, -0.00054799,\n",
       "        0.00642278, -0.00251381, -0.0015818 , -0.00567879,  0.00047015,\n",
       "        0.01045062,  0.00406057, -0.00143184, -0.00717954,  0.00099939,\n",
       "       -0.01271691,  0.00910462,  0.00190046, -0.00181194,  0.01131755,\n",
       "       -0.00796397,  0.00662326, -0.0082667 , -0.0094371 ,  0.00651675,\n",
       "       -0.00463959, -0.00342465, -0.01023663,  0.00103908, -0.00452033,\n",
       "       -0.00389306,  0.01080714,  0.0137351 ,  0.00345716,  0.00102855,\n",
       "       -0.00064555,  0.00885472, -0.00526954,  0.00702048,  0.01617834,\n",
       "        0.00886187,  0.00039672,  0.00180124,  0.0084597 , -0.00655955],\n",
       "      dtype=float32)<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"IAcfjUqvoeqePwh9JjBX8y",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model.save(\"discord_chat_word2vec.model\")"
   ],
   "execution_count":45,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"qLStGVG8xLm33sAmhMLAK0",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "similar_words = model.wv.most_similar(\"masters\")\n",
    "similar_words"
   ],
   "execution_count":66,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "[('data', 0.35552290081977844),\n",
       " ('ml', 0.32721826434135437),\n",
       " ('fun', 0.3038480281829834),\n",
       " ('join', 0.29089614748954773),\n",
       " ('strong', 0.2808547616004944),\n",
       " ('goal', 0.269493967294693),\n",
       " ('end', 0.261987566947937),\n",
       " ('creating', 0.26140421628952026),\n",
       " ('4th', 0.26119503378868103),\n",
       " ('mostly', 0.2549818456172943)]"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"0sVDUSJR0MeniprgTOM3X8",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model.wv.most_similar(positive=[\"first\", \"experience\"], negative=[\"masters\"], topn=3)"
   ],
   "execution_count":67,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "[('member', 0.5822976231575012),\n",
       " ('good', 0.5815702676773071),\n",
       " ('also', 0.5713886618614197)]"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"78OEMlOSzshco6B698hr6J",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model.wv.doesnt_match(['old', 'new', 'first'])"
   ],
   "execution_count":70,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "'first'"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"BwRYOx50zLC86kFy6NDj0T",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}